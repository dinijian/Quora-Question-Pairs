{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\Dell\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Unzipping corpora\\stopwords.zip.\n"
     ]
    }
   ],
   "source": [
    "#importing Libraries\n",
    "\n",
    "import numpy as np\n",
    "# Powerful n-dimensional arrays. Numerical computing tools\n",
    "import pandas as pd\n",
    "# is a fast, powerful, flexible and easy to use open source data analysis and manipulation tool\n",
    "import seaborn as sns\n",
    "# Seaborn is a Python data visualization library based on matplotlib.\n",
    "import matplotlib.pyplot as plt\n",
    "# Matplotlib is a comprehensive library for creating static, animated, and interactive visualizations in Python\n",
    "from subprocess import check_output\n",
    "# The subprocess is used to run new applications or programs through Python code by creating new processes.\n",
    "# It also helps to obtain the input/output/error pipes as well as the exit codes of various commands\n",
    "%matplotlib inline\n",
    "#With this backend, the output of plotting commands is displayed inline within frontends \n",
    "#like the Jupyter notebook\n",
    "#import plotly.offline as py\n",
    "#plotly enables Python users to create beautiful interactive web-based visualizations\n",
    "#py.init_notebook_mode(connected=True)\n",
    "#to plot plotply ..\n",
    "#import plotly.graph_objs as go\n",
    "#import plotly.tools as tls\n",
    "import os\n",
    "#It imports the OS library, which is mainly useful to do OS stuff (bet that was really helpful to you!)\n",
    "#OS stuff includes: showing the absolute path of a file\n",
    "#import gc\n",
    "#Python's garbage collector runs during program execution and is triggered when an object's reference count reaches zero.\n",
    "import re\n",
    "#a regular expression is denoted as RE \n",
    "from nltk.corpus import stopwords\n",
    "# stopwords \n",
    "#NLTK is a leading platform for building Python programs to work with human language data. \n",
    "import distance\n",
    "from nltk.stem import PorterStemmer\n",
    "#The Porter stemming algorithm (or 'Porter stemmer') is a process for removing the commoner morphological \n",
    "#and inflexional endings from words in English\n",
    "from bs4 import BeautifulSoup\n",
    "#Beautiful Soup is a Python library for pulling data out of HTML and XML files.\n",
    "from fuzzywuzzy import fuzz\n",
    "from sklearn.manifold import TSNE\n",
    "# Import the Required lib packages for WORD-Cloud generation\n",
    "# https://stackoverflow.com/questions/45625434/how-to-install-wordcloud-in-python3-6\n",
    "from wordcloud import WordCloud, STOPWORDS\n",
    "import nltk\n",
    "nltk.download('stopwords')\n",
    "from os import path\n",
    "#from PIL import Imagedf = pd.read_csv(\"minor/DataSet/Quora.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"Quora.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.fillna(' ')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>qid1</th>\n",
       "      <th>qid2</th>\n",
       "      <th>question1</th>\n",
       "      <th>question2</th>\n",
       "      <th>is_duplicate</th>\n",
       "      <th>freq_qid1</th>\n",
       "      <th>freq_qid2</th>\n",
       "      <th>q1_len</th>\n",
       "      <th>q2_len</th>\n",
       "      <th>q1_n_words</th>\n",
       "      <th>q2_n_words</th>\n",
       "      <th>word_common</th>\n",
       "      <th>word_total</th>\n",
       "      <th>word_share</th>\n",
       "      <th>freq_q1+freq_q2</th>\n",
       "      <th>freq_q1-freq_q2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>What is the step by step guide to invest in sh...</td>\n",
       "      <td>What is the step by step guide to invest in sh...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>66</td>\n",
       "      <td>57</td>\n",
       "      <td>14</td>\n",
       "      <td>12</td>\n",
       "      <td>10.0</td>\n",
       "      <td>23.0</td>\n",
       "      <td>0.434783</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>What is the story of Kohinoor (Koh-i-Noor) Dia...</td>\n",
       "      <td>What would happen if the Indian government sto...</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>51</td>\n",
       "      <td>88</td>\n",
       "      <td>8</td>\n",
       "      <td>13</td>\n",
       "      <td>4.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>How can I increase the speed of my internet co...</td>\n",
       "      <td>How can Internet speed be increased by hacking...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>73</td>\n",
       "      <td>59</td>\n",
       "      <td>14</td>\n",
       "      <td>10</td>\n",
       "      <td>4.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>8</td>\n",
       "      <td>Why am I mentally very lonely? How can I solve...</td>\n",
       "      <td>Find the remainder when [math]23^{24}[/math] i...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>50</td>\n",
       "      <td>65</td>\n",
       "      <td>11</td>\n",
       "      <td>9</td>\n",
       "      <td>0.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>9</td>\n",
       "      <td>10</td>\n",
       "      <td>Which one dissolve in water quikly sugar, salt...</td>\n",
       "      <td>Which fish would survive in salt water?</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>76</td>\n",
       "      <td>39</td>\n",
       "      <td>13</td>\n",
       "      <td>7</td>\n",
       "      <td>2.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id  qid1  qid2                                          question1  \\\n",
       "0   0     1     2  What is the step by step guide to invest in sh...   \n",
       "1   1     3     4  What is the story of Kohinoor (Koh-i-Noor) Dia...   \n",
       "2   2     5     6  How can I increase the speed of my internet co...   \n",
       "3   3     7     8  Why am I mentally very lonely? How can I solve...   \n",
       "4   4     9    10  Which one dissolve in water quikly sugar, salt...   \n",
       "\n",
       "                                           question2  is_duplicate  freq_qid1  \\\n",
       "0  What is the step by step guide to invest in sh...             0          1   \n",
       "1  What would happen if the Indian government sto...             0          4   \n",
       "2  How can Internet speed be increased by hacking...             0          1   \n",
       "3  Find the remainder when [math]23^{24}[/math] i...             0          1   \n",
       "4            Which fish would survive in salt water?             0          3   \n",
       "\n",
       "   freq_qid2  q1_len  q2_len  q1_n_words  q2_n_words  word_common  word_total  \\\n",
       "0          1      66      57          14          12         10.0        23.0   \n",
       "1          1      51      88           8          13          4.0        20.0   \n",
       "2          1      73      59          14          10          4.0        24.0   \n",
       "3          1      50      65          11           9          0.0        19.0   \n",
       "4          1      76      39          13           7          2.0        20.0   \n",
       "\n",
       "   word_share  freq_q1+freq_q2  freq_q1-freq_q2  \n",
       "0    0.434783                2                0  \n",
       "1    0.200000                5                3  \n",
       "2    0.166667                2                0  \n",
       "3    0.000000                2                0  \n",
       "4    0.100000                4                2  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "if os.path.isfile(\"df_features_train.csv\"):\n",
    "    df = pd.read_csv(\"df_features_train.csv\",encoding='latin-1')\n",
    "else:    \n",
    "    df['freq_qid1'] = df.groupby('qid1')['qid1'].transform('count')\n",
    "    df['freq_qid2'] = df.groupby('qid2')['qid2'].transform('count')\n",
    "    df['q1_len'] = df['question1'].str.len()\n",
    "    df['q2_len'] = df['question2'].str.len()\n",
    "    \n",
    "    df['q1_n_words'] = df['question1'].apply(lambda row: len(row.split(\" \")))\n",
    "    df['q2_n_words'] = df['question2'].apply(lambda row: len(row.split(\" \")))\n",
    "    \n",
    "    def word_common(row):\n",
    "        w1 = set(map(lambda word : word.lower().strip(),row['question1'].split(' ')))\n",
    "        w2 = set(map(lambda word : word.lower().strip(),row['question2'].split(' ')))\n",
    "        return 1.0 * len(w1&w2)\n",
    "    df['word_common'] = df.apply(word_common,axis = 1)\n",
    "    \n",
    "    def word_total(row):\n",
    "        w1 = set(map(lambda word : word.lower().strip(),row['question1'].split(' ')))\n",
    "        w2 = set(map(lambda word : word.lower().strip(),row['question2'].split(' ')))\n",
    "        return 1.0 * (len(w1) + len(w2))\n",
    "    df['word_total'] = df.apply(word_total,axis=1)\n",
    "    \n",
    "    def word_share(row):\n",
    "        w1 = set(map(lambda word : word.lower().strip(),row['question1'].split(' ')))\n",
    "        w2 = set(map(lambda word : word.lower().strip(),row['question2'].split(' ')))\n",
    "        return 1.0*( len(w1 & w2)/(len(w1)+len(w2)))\n",
    "    df['word_share'] = df.apply(word_share,axis=1)\n",
    "    \n",
    "    df['freq_q1+freq_q2'] = df['freq_qid1'] + df['freq_qid2']\n",
    "    df['freq_q1-freq_q2'] = abs(df['freq_qid1'] - df['freq_qid2'])\n",
    "    \n",
    "    df.to_csv('df_features_train.csv',index='False')\n",
    "    \n",
    "df.head()   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def word_first(row):\n",
    "        w1 = row['question1'].split(' ')[0].lower()\n",
    "        w2 = row['question2'].split(' ')[0].lower()\n",
    "        return w1,w2,w1==w2\n",
    "tup = (df.apply(word_first,axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "STOP_WORDS = stopwords.words(\"english\") # is // the // very  // not  // to  \n",
    "def preprocess(x):\n",
    "    x = str(x).lower()\n",
    "    #stack exch\n",
    "    x = x.replace(\",000,000\", \"m\").replace(\",000\", \"k\").replace(\"′\", \"'\").replace(\"’\", \"'\")\\\n",
    "                           .replace(\"won't\", \"will not\").replace(\"cannot\", \"can not\").replace(\"can't\", \"can not\")\\\n",
    "                           .replace(\"n't\", \" not\").replace(\"what's\", \"what is\").replace(\"it's\", \"it is\")\\\n",
    "                           .replace(\"'ve\", \" have\").replace(\"i'm\", \"i am\").replace(\"'re\", \" are\")\\\n",
    "                           .replace(\"he's\", \"he is\").replace(\"she's\", \"she is\").replace(\"'s\", \" own\")\\\n",
    "                           .replace(\"%\", \" percent \").replace(\"₹\", \" rupee \").replace(\"$\", \" dollar \")\\\n",
    "                           .replace(\"€\", \" euro \").replace(\"'ll\", \" will\")\n",
    "    \n",
    "    # replacing millions 1m and thosands by 1k\n",
    "    x = re.sub(r\"([0-9]+)000000\", r\"\\1m\", x)\n",
    "    \n",
    "    x = re.sub(r\"([0-9]+)000\", r\"\\1k\", x)\n",
    "    \n",
    "    \n",
    "    porter = PorterStemmer()\n",
    "    #######\n",
    "    pattern = re.compile('\\W')\n",
    "\n",
    "    if type(x) == type(''):\n",
    "        x = re.sub(pattern, ' ', x)\n",
    "# beauti : beautiful   \n",
    "    if type(x) == type(''):\n",
    "        x = porter.stem(x)\n",
    "        soup = BeautifulSoup(x)\n",
    "        x = soup.get_text()\n",
    "        \n",
    "    return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_features(q1,q2):\n",
    "    # 10 list that will contain feature \n",
    "    token_features = [0.0]*10\n",
    "    SAFE_DIV = 0.0001\n",
    "    # Converting the Sentence into Tokens: \n",
    "    q1_tokens = q1.split()\n",
    "    q2_tokens = q2.split()\n",
    "# FUZZY - SIMILAR \n",
    "    # Q1 NEW YORK MEaTs    fuzzy ratio good\n",
    "    # Q2 NEW YORK MEATS\n",
    "    #dISTANCE FEATURE /// EDITS Fuzzy ratio  \n",
    "    # NO OF EDITS GOOD FUZZY RATIO\n",
    "    #  0-100\n",
    "    # Similar to string matching problem learned in dynamic programming\n",
    "    # string 1 YANKEES , NEW YORK YANKEES \n",
    "    # string 2 NEWYORK METS NEW YORK YANKEES\n",
    "    # fuuzz partial ratio # substring matches\n",
    "    # token sort ..\n",
    "    # \"csk vs rcb\"   \n",
    "    # \"rcb vs csk\"   partial ratio ... \n",
    "    # csk , vs , rcb # sort     \n",
    "    # csk vs rcb  # 80 - 90  3 \n",
    "    # csk vs rcb , had a great match today and ............  200\n",
    "    # token set ratio\n",
    "    #t1 = [sorted intersection]\n",
    "    # t2 = ..... + remaining s1  ->''\n",
    "    # t3 = ...... + remaining of s2 -> 'had a great match.......'\n",
    "    # t1 , t2 , t3 ratio similarity ..... \n",
    "    if len(q1_tokens) == 0 or len(q2_tokens) == 0:\n",
    "        return token_features\n",
    "    # Get the non-stopwords in Questions\n",
    "    q1_words = set([word for word in q1_tokens if word not in STOP_WORDS])\n",
    "    q2_words = set([word for word in q2_tokens if word not in STOP_WORDS])\n",
    "    \n",
    "    #Get the stopwords in Questions\n",
    "    q1_stops = set([word for word in q1_tokens if word in STOP_WORDS])\n",
    "    q2_stops = set([word for word in q2_tokens if word in STOP_WORDS])\n",
    "    \n",
    "    # Get the common non-stopwords from Question pair\n",
    "    common_word_count = len(q1_words.intersection(q2_words))\n",
    "    \n",
    "    # Get the common stopwords from Question pair\n",
    "    common_stop_count = len(q1_stops.intersection(q2_stops))\n",
    "    \n",
    "    # Get the common Tokens from Question pair\n",
    "    common_token_count = len(set(q1_tokens).intersection(set(q2_tokens)))\n",
    "    \n",
    "    \n",
    "    token_features[0] = common_word_count / (min(len(q1_words), len(q2_words)) + SAFE_DIV)\n",
    "    token_features[1] = common_word_count / (max(len(q1_words), len(q2_words)) + SAFE_DIV)\n",
    "    token_features[2] = common_stop_count / (min(len(q1_stops), len(q2_stops)) + SAFE_DIV)\n",
    "    token_features[3] = common_stop_count / (max(len(q1_stops), len(q2_stops)) + SAFE_DIV)\n",
    "    token_features[4] = common_token_count / (min(len(q1_tokens), len(q2_tokens)) + SAFE_DIV)\n",
    "    token_features[5] = common_token_count / (max(len(q1_tokens), len(q2_tokens)) + SAFE_DIV)\n",
    "    \n",
    "    # Last word of both question is same or not\n",
    "    token_features[6] = int(q1_tokens[-1] == q2_tokens[-1])\n",
    "    \n",
    "    # First word of both question is same or not\n",
    "    token_features[7] = int(q1_tokens[0] == q2_tokens[0])\n",
    "    \n",
    "    token_features[8] = abs(len(q1_tokens) - len(q2_tokens))\n",
    "    \n",
    "    #Average Token Length of both Questions\n",
    "    token_features[9] = (len(q1_tokens) + len(q2_tokens))/2\n",
    "    return token_features\n",
    "\n",
    "\n",
    "def get_longest_substr_ratio(a,b):\n",
    "    strs = list(distance.lcsubstrings(a,b))\n",
    "    if(len(strs)==0):\n",
    "        return 0\n",
    "    else:\n",
    "        return len(strs[0]) / (min(len(a),len(b))+1)\n",
    "    \n",
    "def extract_features(df):\n",
    "    # preprocessing\n",
    "    df[\"question1\"] = df[\"question1\"].fillna(\"\").apply(preprocess)\n",
    "    df[\"question2\"] = df[\"question2\"].fillna(\"\").apply(preprocess)\n",
    "    \n",
    "    print(\"token features\")\n",
    "    \n",
    "    token_feature = df.apply((lambda x: get_features(x[\"question1\"],x[\"question2\"])),axis=1)\n",
    "    \n",
    "    df['cwc_min'] = list(map(lambda x : x[0], token_feature))\n",
    "    df['cwc_max'] = list(map(lambda x : x[1], token_feature))\n",
    "    df['csc_min'] = list(map(lambda x : x[2], token_feature))\n",
    "    df['csc_max'] = list(map(lambda x : x[3], token_feature))\n",
    "    df['ctc_min'] = list(map(lambda x : x[4], token_feature))\n",
    "    df['ctc_max'] = list(map(lambda x : x[5], token_feature))\n",
    "    df['last_word_eq'] = list(map(lambda x : x[6], token_feature))\n",
    "    df['first_word_eq'] = list(map(lambda x : x[7], token_feature))\n",
    "    df['abs_len_diff'] = list(map(lambda x: x[8] , token_feature))\n",
    "    df['mean_len'] =  list(map(lambda x : x[7], token_feature))\n",
    "    \n",
    "    print(\"fuzzy features..\")\n",
    "\n",
    "    df[\"token_set_ratio\"]       = df.apply(lambda x: fuzz.token_set_ratio(x[\"question1\"], x[\"question2\"]), axis=1)\n",
    "    # The token sort approach involves tokenizing the string in question, sorting the tokens alphabetically, and \n",
    "    # then joining them back into a string We then compare the transformed strings with a simple ratio().\n",
    "    df[\"token_sort_ratio\"]      = df.apply(lambda x: fuzz.token_sort_ratio(x[\"question1\"], x[\"question2\"]), axis=1)\n",
    "    df[\"fuzz_ratio\"]            = df.apply(lambda x: fuzz.QRatio(x[\"question1\"], x[\"question2\"]), axis=1)\n",
    "    df[\"fuzz_partial_ratio\"]    = df.apply(lambda x: fuzz.partial_ratio(x[\"question1\"], x[\"question2\"]), axis=1)\n",
    "    df[\"longest_substr_ratio\"]  = df.apply(lambda x: get_longest_substr_ratio(x[\"question1\"], x[\"question2\"]), axis=1)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting features for train:\n",
      "token features\n",
      "fuzzy features..\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>qid1</th>\n",
       "      <th>qid2</th>\n",
       "      <th>question1</th>\n",
       "      <th>question2</th>\n",
       "      <th>is_duplicate</th>\n",
       "      <th>cwc_min</th>\n",
       "      <th>cwc_max</th>\n",
       "      <th>csc_min</th>\n",
       "      <th>csc_max</th>\n",
       "      <th>...</th>\n",
       "      <th>ctc_max</th>\n",
       "      <th>last_word_eq</th>\n",
       "      <th>first_word_eq</th>\n",
       "      <th>abs_len_diff</th>\n",
       "      <th>mean_len</th>\n",
       "      <th>token_set_ratio</th>\n",
       "      <th>token_sort_ratio</th>\n",
       "      <th>fuzz_ratio</th>\n",
       "      <th>fuzz_partial_ratio</th>\n",
       "      <th>longest_substr_ratio</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>what is the step by step guide to invest in sh...</td>\n",
       "      <td>what is the step by step guide to invest in sh...</td>\n",
       "      <td>0</td>\n",
       "      <td>0.999980</td>\n",
       "      <td>0.833319</td>\n",
       "      <td>0.999983</td>\n",
       "      <td>0.999983</td>\n",
       "      <td>...</td>\n",
       "      <td>0.785709</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>100</td>\n",
       "      <td>93</td>\n",
       "      <td>93</td>\n",
       "      <td>100</td>\n",
       "      <td>0.982759</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>what is the story of kohinoor  koh i noor  dia...</td>\n",
       "      <td>what would happen if the indian government sto...</td>\n",
       "      <td>0</td>\n",
       "      <td>0.799984</td>\n",
       "      <td>0.399996</td>\n",
       "      <td>0.749981</td>\n",
       "      <td>0.599988</td>\n",
       "      <td>...</td>\n",
       "      <td>0.466664</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>86</td>\n",
       "      <td>63</td>\n",
       "      <td>66</td>\n",
       "      <td>75</td>\n",
       "      <td>0.596154</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2 rows × 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   id  qid1  qid2                                          question1  \\\n",
       "0   0     1     2  what is the step by step guide to invest in sh...   \n",
       "1   1     3     4  what is the story of kohinoor  koh i noor  dia...   \n",
       "\n",
       "                                           question2  is_duplicate   cwc_min  \\\n",
       "0  what is the step by step guide to invest in sh...             0  0.999980   \n",
       "1  what would happen if the indian government sto...             0  0.799984   \n",
       "\n",
       "    cwc_max   csc_min   csc_max  ...   ctc_max  last_word_eq  first_word_eq  \\\n",
       "0  0.833319  0.999983  0.999983  ...  0.785709           0.0            1.0   \n",
       "1  0.399996  0.749981  0.599988  ...  0.466664           0.0            1.0   \n",
       "\n",
       "   abs_len_diff  mean_len  token_set_ratio  token_sort_ratio  fuzz_ratio  \\\n",
       "0           2.0       1.0              100                93          93   \n",
       "1           5.0       1.0               86                63          66   \n",
       "\n",
       "   fuzz_partial_ratio  longest_substr_ratio  \n",
       "0                 100              0.982759  \n",
       "1                  75              0.596154  \n",
       "\n",
       "[2 rows x 21 columns]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "if os.path.isfile('minor/Files/nlp_features_train.csv'):\n",
    "    df = pd.read_csv(\"minor/Files/nlp_features_train.csv\",encoding='latin-1')\n",
    "    df.fillna('')\n",
    "else:\n",
    "    print(\"Extracting features for train:\")\n",
    "    df = pd.read_csv(\"Quora.csv\")\n",
    "    df = extract_features(df)\n",
    "    df.to_csv(\"Files/nlp_features_train.csv\", index=False)\n",
    "df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
