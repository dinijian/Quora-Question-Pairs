{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import time\n",
    "import warnings\n",
    "import numpy as np\n",
    "from nltk.corpus import stopwords\n",
    "from sklearn.preprocessing import normalize\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "import sys\n",
    "import os \n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import spacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# converting strings into unicode\n",
    "df = pd.read_csv('Quora.csv')\n",
    "\n",
    "df['question1']= df['question1'].apply(lambda x : str(x));\n",
    "df['question2'] = df['question2'].apply(lambda x : str(x));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Applying Tf- iDF\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "questions = list(df['question1'] + df['question2'])\n",
    "tf = TfidfVectorizer(lowercase=False,)\n",
    "tf.fit_transform(questions)\n",
    "\n",
    "word2tfidf = dict(zip(tf.get_feature_names(),tf.idf_)) #DOUBT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import en_core_web_sm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = en_core_web_sm.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████| 404290/404290 [1:38:16<00:00, 68.57it/s]\n"
     ]
    }
   ],
   "source": [
    "#contains final for questions \n",
    "vect1 = []\n",
    "#DOUBT\n",
    "for question in tqdm(list(df['question1'])):\n",
    "    doc1 = nlp(question)\n",
    "    \n",
    "    ques_mean1 = np.zeros([len(doc1),len(doc1[0].vector)]) \n",
    "    for word in doc1:\n",
    "        w1 = word.vector\n",
    "        \n",
    "        try:\n",
    "            idf = word2tfidf[str(word)]\n",
    "        except:\n",
    "            idf = 0\n",
    "            \n",
    "        ques_mean1 += w1*idf\n",
    "    ques_mean1 = ques_mean1.mean(axis = 0)\n",
    "    vect1.append(ques_mean1)\n",
    "df['q1_feat_tf'] = list(vect1)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████| 404290/404290 [2:43:55<00:00, 41.10it/s]\n"
     ]
    }
   ],
   "source": [
    "#contains final for questions \n",
    "vect2 = []\n",
    "\n",
    "for question in tqdm(list(df['question2'])):\n",
    "    doc2 = nlp(question)\n",
    "    \n",
    "    ques_mean2 = np.zeros([len(doc2),len(doc2[0].vector)]) \n",
    "    for word in doc2:\n",
    "        w2 = word.vector\n",
    "        \n",
    "        try:\n",
    "            idf = word2tfidf[str(word)]\n",
    "        except:\n",
    "            idf = 0\n",
    "            \n",
    "        ques_mean2 += w2*idf\n",
    "    ques_mean2 = ques_mean2.mean(axis = 0)\n",
    "    vect2.append(ques_mean2)\n",
    "df['q2_feat_tf'] = list(vect2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_pickle('Files/spacy.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "if os.path.isfile('Files/spacy.csv'):#where is spacy file saved?\n",
    "    df_spacy = pd.read_pickle('Files/spacy.csv')\n",
    "else :\n",
    "    print(\"Run from the beginning of the file\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "if os.path.isfile('Files/nlp_features_train.csv'):\n",
    "    df_nlp = pd.read_csv('Files/nlp_features_train.csv',encoding='latin-1') #will it work if directly download files? or have to run\n",
    "else :\n",
    "    print(\"The nlp data set features are not found\")\n",
    "    \n",
    "if os.path.isfile('Files/df_features_train.csv'):\n",
    "    df_basic = pd.read_csv('Files/df_features_train.csv') #WHICH FILES??\n",
    "else:\n",
    "    print(\"Df_features_train.csv not found\")\n",
    "    print('_________________EXIT___________________')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "df1 = df_nlp.drop(['qid1','qid2','question1','question2'],axis=1)#DOUBT\n",
    "df2 = df_basic.drop(['qid1','qid2','question1','question2','is_duplicate'],axis=1)\n",
    "df3 = df_spacy.drop(['qid1','qid2','question1','question2','is_duplicate'],axis = 1)\n",
    "\n",
    "# Hence getting Each 300+ features as individual property\n",
    "df_q1_feat = pd.DataFrame(df3.q1_feat_tf.values.tolist(),index=df3.index)\n",
    "df_q2_feat = pd.DataFrame(df3.q2_feat_tf.values.tolist(),index=df3.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>86</th>\n",
       "      <th>87</th>\n",
       "      <th>88</th>\n",
       "      <th>89</th>\n",
       "      <th>90</th>\n",
       "      <th>91</th>\n",
       "      <th>92</th>\n",
       "      <th>93</th>\n",
       "      <th>94</th>\n",
       "      <th>95</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-20.420960</td>\n",
       "      <td>25.809565</td>\n",
       "      <td>-120.875930</td>\n",
       "      <td>-120.089934</td>\n",
       "      <td>47.743297</td>\n",
       "      <td>82.881647</td>\n",
       "      <td>13.692647</td>\n",
       "      <td>-2.328330</td>\n",
       "      <td>-56.527910</td>\n",
       "      <td>-141.456537</td>\n",
       "      <td>...</td>\n",
       "      <td>-81.454172</td>\n",
       "      <td>95.711299</td>\n",
       "      <td>23.484497</td>\n",
       "      <td>71.713856</td>\n",
       "      <td>-15.987871</td>\n",
       "      <td>-5.651370</td>\n",
       "      <td>132.943438</td>\n",
       "      <td>-133.359732</td>\n",
       "      <td>12.202677</td>\n",
       "      <td>-20.588167</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-103.531553</td>\n",
       "      <td>74.353032</td>\n",
       "      <td>-131.535842</td>\n",
       "      <td>-121.343942</td>\n",
       "      <td>-28.826116</td>\n",
       "      <td>71.306030</td>\n",
       "      <td>21.399175</td>\n",
       "      <td>16.965575</td>\n",
       "      <td>-3.343543</td>\n",
       "      <td>-34.434352</td>\n",
       "      <td>...</td>\n",
       "      <td>-146.823464</td>\n",
       "      <td>53.217788</td>\n",
       "      <td>109.906141</td>\n",
       "      <td>65.295377</td>\n",
       "      <td>-127.780162</td>\n",
       "      <td>5.002112</td>\n",
       "      <td>59.177660</td>\n",
       "      <td>-120.263983</td>\n",
       "      <td>-71.359894</td>\n",
       "      <td>20.966675</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-93.197456</td>\n",
       "      <td>-97.906234</td>\n",
       "      <td>-77.455222</td>\n",
       "      <td>-125.958146</td>\n",
       "      <td>57.201867</td>\n",
       "      <td>51.768824</td>\n",
       "      <td>1.641915</td>\n",
       "      <td>39.578487</td>\n",
       "      <td>23.169117</td>\n",
       "      <td>-57.100650</td>\n",
       "      <td>...</td>\n",
       "      <td>-105.966230</td>\n",
       "      <td>118.966684</td>\n",
       "      <td>38.612364</td>\n",
       "      <td>85.922869</td>\n",
       "      <td>-52.499269</td>\n",
       "      <td>32.288933</td>\n",
       "      <td>-5.439048</td>\n",
       "      <td>-115.920739</td>\n",
       "      <td>-5.230780</td>\n",
       "      <td>-3.932547</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>8.359163</td>\n",
       "      <td>-62.501191</td>\n",
       "      <td>-98.837463</td>\n",
       "      <td>-30.157859</td>\n",
       "      <td>26.721602</td>\n",
       "      <td>130.996214</td>\n",
       "      <td>7.831641</td>\n",
       "      <td>38.369273</td>\n",
       "      <td>-25.347790</td>\n",
       "      <td>-41.314360</td>\n",
       "      <td>...</td>\n",
       "      <td>59.643758</td>\n",
       "      <td>24.050001</td>\n",
       "      <td>-67.307009</td>\n",
       "      <td>21.425892</td>\n",
       "      <td>48.925113</td>\n",
       "      <td>-84.020696</td>\n",
       "      <td>28.958123</td>\n",
       "      <td>-61.928086</td>\n",
       "      <td>-79.103757</td>\n",
       "      <td>4.287268</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-72.378577</td>\n",
       "      <td>1.436893</td>\n",
       "      <td>-180.962019</td>\n",
       "      <td>-214.450679</td>\n",
       "      <td>133.476621</td>\n",
       "      <td>13.439506</td>\n",
       "      <td>-38.458427</td>\n",
       "      <td>100.236844</td>\n",
       "      <td>79.266830</td>\n",
       "      <td>-198.363985</td>\n",
       "      <td>...</td>\n",
       "      <td>-129.560201</td>\n",
       "      <td>164.730044</td>\n",
       "      <td>34.722580</td>\n",
       "      <td>129.237790</td>\n",
       "      <td>-31.972835</td>\n",
       "      <td>141.800667</td>\n",
       "      <td>105.816798</td>\n",
       "      <td>-165.177456</td>\n",
       "      <td>-62.618496</td>\n",
       "      <td>-153.124696</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 96 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           0          1           2           3           4           5   \\\n",
       "0  -20.420960  25.809565 -120.875930 -120.089934   47.743297   82.881647   \n",
       "1 -103.531553  74.353032 -131.535842 -121.343942  -28.826116   71.306030   \n",
       "2  -93.197456 -97.906234  -77.455222 -125.958146   57.201867   51.768824   \n",
       "3    8.359163 -62.501191  -98.837463  -30.157859   26.721602  130.996214   \n",
       "4  -72.378577   1.436893 -180.962019 -214.450679  133.476621   13.439506   \n",
       "\n",
       "          6           7          8           9   ...          86          87  \\\n",
       "0  13.692647   -2.328330 -56.527910 -141.456537  ...  -81.454172   95.711299   \n",
       "1  21.399175   16.965575  -3.343543  -34.434352  ... -146.823464   53.217788   \n",
       "2   1.641915   39.578487  23.169117  -57.100650  ... -105.966230  118.966684   \n",
       "3   7.831641   38.369273 -25.347790  -41.314360  ...   59.643758   24.050001   \n",
       "4 -38.458427  100.236844  79.266830 -198.363985  ... -129.560201  164.730044   \n",
       "\n",
       "           88          89          90          91          92          93  \\\n",
       "0   23.484497   71.713856  -15.987871   -5.651370  132.943438 -133.359732   \n",
       "1  109.906141   65.295377 -127.780162    5.002112   59.177660 -120.263983   \n",
       "2   38.612364   85.922869  -52.499269   32.288933   -5.439048 -115.920739   \n",
       "3  -67.307009   21.425892   48.925113  -84.020696   28.958123  -61.928086   \n",
       "4   34.722580  129.237790  -31.972835  141.800667  105.816798 -165.177456   \n",
       "\n",
       "          94          95  \n",
       "0  12.202677  -20.588167  \n",
       "1 -71.359894   20.966675  \n",
       "2  -5.230780   -3.932547  \n",
       "3 -79.103757    4.287268  \n",
       "4 -62.618496 -153.124696  \n",
       "\n",
       "[5 rows x 96 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_q1_feat.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# storing the final features to csv file\n",
    "if not os.path.isfile('final_features.csv'):\n",
    "    df_q1_feat['id']=df1['id']\n",
    "    df_q2_feat['id']=df1['id']\n",
    "    df1  = df1.merge(df2, on='id',how='left')\n",
    "    df2  = df_q1_feat.merge(df_q2_feat, on='id',how='left')\n",
    "    result  = df1.merge(df2, on='id',how='left')\n",
    "    result.to_csv('Files/final_features.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
